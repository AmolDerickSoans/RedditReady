{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement requirments.txt (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for requirments.txt\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requirments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an environment variable\n",
    "os.environ['REDDIT_CLIENT_ID'] = 'HebCVdDt8qct1oxNiyK1cQ'\n",
    "os.environ['REDDIT_CLIENT_SECRET'] = 'mgjtqYGDFme3CDXo27KgJ1Kvwn5QrA'\n",
    "os.environ['REDDIT_USER_AGENT'] = 'python:com.myapp.redditresearch:v1.0 (by /u/Eastern-Spend5113)'\n",
    "os.environ['REDDIT_USERNAME'] = 'Eastern-Spend5113'\n",
    "os.environ['REDDIT_PASSWORD'] = 'derick.2000!'\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCUm-ht8pdWuAjRDsbIjBOSj3vPCQyRavQ'\n",
    "# Access an environment variable\n",
    "client_id = os.environ.get('REDDIT_CLIENT_ID')\n",
    "print(client_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "from textblob import TextBlob\n",
    "import nest_asyncio\n",
    "import praw\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Gemini\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the Reddit Research Agent\"\"\"\n",
    "    monitoring_duration: int = 21600  # 6 hours in seconds\n",
    "    check_interval: int = 3600  # 1 hour in seconds\n",
    "    max_replies_per_thread: int = 4\n",
    "    upvote_ratio_threshold: float = 0.05\n",
    "    rate_limit_delay: int = 120  # seconds between API calls\n",
    "    min_upvotes: int = 5\n",
    "\n",
    "@dataclass\n",
    "class ResearchData:\n",
    "    \"\"\"Structure for storing research data\"\"\"\n",
    "    research_id: str\n",
    "    original_prompt: str\n",
    "    subreddit: str\n",
    "    style_template: str\n",
    "    post: Dict\n",
    "    interactions: Dict\n",
    "    \n",
    "    def to_json(self) -> str:\n",
    "        \"\"\"Convert the research data to JSON string\"\"\"\n",
    "        return json.dumps(asdict(self), indent=2)\n",
    "\n",
    "class GeminiWrapper:\n",
    "    \"\"\"Wrapper for Gemini API interactions\"\"\"\n",
    "    def __init__(self, temperature=0.6):\n",
    "        self.model = genai.GenerativeModel(\n",
    "            model_name='gemini-pro',\n",
    "            generation_config={\n",
    "                'temperature': temperature,\n",
    "                'top_p': 0.9,\n",
    "                'top_k': 40,\n",
    "                'max_output_tokens': 2048,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    async def generate_text(self, prompt: str) -> str:\n",
    "        \"\"\"Generate text using Gemini\"\"\"\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating text with Gemini: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "class RedditAPI:\n",
    "    \"\"\"Handler for Reddit API interactions\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reddit = praw.Reddit(\n",
    "            client_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "            client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n",
    "            user_agent=os.getenv('REDDIT_USER_AGENT'),\n",
    "            username=os.getenv('REDDIT_USERNAME'),\n",
    "            password=os.getenv('REDDIT_PASSWORD')\n",
    "        )\n",
    "        self.last_api_call = 0\n",
    "        \n",
    "    def _respect_rate_limit(self):\n",
    "        \"\"\"Ensure we don't exceed Reddit's rate limits\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last_call = current_time - self.last_api_call\n",
    "        if time_since_last_call < Config.rate_limit_delay:\n",
    "            time.sleep(Config.rate_limit_delay - time_since_last_call)\n",
    "        self.last_api_call = time.time()\n",
    "\n",
    "    def get_subreddit(self, subreddit_name: str) -> Optional[praw.models.Subreddit]:\n",
    "        \"\"\"Safely get a subreddit instance\"\"\"\n",
    "        self._respect_rate_limit()\n",
    "        try:\n",
    "            subreddit = self.reddit.subreddit(subreddit_name)\n",
    "            # Test if the subreddit is accessible\n",
    "            subreddit.title\n",
    "            return subreddit\n",
    "        except praw.exceptions.RedditAPIException:\n",
    "            print(f\"Error: '{praw.exceptions.RedditAPIException}' \")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error accessing subreddit: {str(e)}\")\n",
    "            return None\n",
    "        # Verification function to check environment variables\n",
    "    def verify_reddit_credentials(self):\n",
    "        \"\"\"Verify that all required Reddit API credentials are set\"\"\"\n",
    "        required_vars = [\n",
    "            'REDDIT_CLIENT_ID',\n",
    "            'REDDIT_CLIENT_SECRET',\n",
    "            'REDDIT_USER_AGENT',\n",
    "            'REDDIT_USERNAME',\n",
    "            'REDDIT_PASSWORD'\n",
    "        ]\n",
    "        \n",
    "        missing_vars = []\n",
    "        for var in required_vars:\n",
    "            if not os.getenv(var):\n",
    "                missing_vars.append(var)\n",
    "        \n",
    "        if missing_vars:\n",
    "            raise Exception(\n",
    "                \"Missing required environment variables:\\n\"\n",
    "                f\"{', '.join(missing_vars)}\\n\"\n",
    "                \"Please set these in your .env file\"\n",
    "            )\n",
    "\n",
    "            \n",
    "\n",
    "class SubredditAnalysisAgent:\n",
    "    \"\"\"Agent for analyzing subreddit patterns and content style\"\"\"\n",
    "    def __init__(self, gemini: GeminiWrapper):\n",
    "        self.gemini = gemini\n",
    "        \n",
    "    async def analyze_subreddit(self, subreddit: praw.models.Subreddit) -> str:\n",
    "        \"\"\"Analyze subreddit and return posting style template\"\"\"\n",
    "        # Collect recent popular posts\n",
    "        posts = []\n",
    "        for post in subreddit.hot(limit=10):\n",
    "            posts.append({\n",
    "                'title': post.title,\n",
    "                'content': post.selftext if hasattr(post, 'selftext') else '',\n",
    "                'score': post.score\n",
    "            })\n",
    "        \n",
    "        # Generate style template\n",
    "        prompt = \"\"\"\n",
    "        Analyze these recent posts and identify:\n",
    "        1. Common writing styles\n",
    "        2. Typical post structure\n",
    "        3. Popular phrases and terminology\n",
    "        4. Engagement patterns\n",
    "        \n",
    "        Posts:\n",
    "        {}\n",
    "        \n",
    "        Provide a structured template for creating posts in this subreddit.\n",
    "        \"\"\".format(json.dumps(posts, indent=2))\n",
    "        \n",
    "        return await self.gemini.generate_text(prompt)\n",
    "\n",
    "class PromptGenerationAgent:\n",
    "    \"\"\"Agent for creating Reddit-optimized posts\"\"\"\n",
    "    def __init__(self, gemini: GeminiWrapper):\n",
    "        self.gemini = gemini\n",
    "    \n",
    "    async def generate_post(self, style_guide: str, research_prompt: str) -> str:\n",
    "        \"\"\"Generate a Reddit post based on style guide and research prompt\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Create a Reddit post following this style guide:\n",
    "        {}\n",
    "        \n",
    "        Research Topic:\n",
    "        {}\n",
    "        \n",
    "        Generate a post that will encourage meaningful discussion and responses.\n",
    "        \"\"\".format(style_guide, research_prompt)\n",
    "        \n",
    "        return await self.gemini.generate_text(prompt)\n",
    "\n",
    "class ResponseAnalysisAgent:\n",
    "    \"\"\"Agent for analyzing and processing responses\"\"\"\n",
    "    def __init__(self, gemini: GeminiWrapper):\n",
    "        self.gemini = gemini\n",
    "        \n",
    "    def analyze_sentiment(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Analyze sentiment of text using TextBlob\"\"\"\n",
    "        analysis = TextBlob(text)\n",
    "        return {\n",
    "            'polarity': analysis.sentiment.polarity,\n",
    "            'subjectivity': analysis.sentiment.subjectivity\n",
    "        }\n",
    "    \n",
    "    def should_reply(self, comment: praw.models.Comment, post_score: int) -> bool:\n",
    "        \"\"\"Determine if a comment warrants a reply\"\"\"\n",
    "        return (\n",
    "            comment.score > Config.min_upvotes and\n",
    "            comment.score > (post_score * Config.upvote_ratio_threshold)\n",
    "        )\n",
    "    \n",
    "    async def generate_reply(self, context: str) -> str:\n",
    "        \"\"\"Generate a reply based on context\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Based on this conversation context:\n",
    "        {}\n",
    "        \n",
    "        Generate a thoughtful and engaging reply that adds value to the discussion.\n",
    "        \"\"\".format(context)\n",
    "        \n",
    "        return await self.gemini.generate_text(prompt)\n",
    "\n",
    "class DataCollectionAgent:\n",
    "    \"\"\"Agent for collecting and storing research data\"\"\"\n",
    "    def __init__(self):\n",
    "        self.data: Dict[str, ResearchData] = {}\n",
    "        \n",
    "    def initialize_research(\n",
    "        self,\n",
    "        research_id: str,\n",
    "        prompt: str,\n",
    "        subreddit: str,\n",
    "        style_template: str\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a new research entry\"\"\"\n",
    "        self.data[research_id] = ResearchData(\n",
    "            research_id=research_id,\n",
    "            original_prompt=prompt,\n",
    "            subreddit=subreddit,\n",
    "            style_template=style_template,\n",
    "            post={},\n",
    "            interactions={\n",
    "                'replies': [],\n",
    "                'metrics': {\n",
    "                    'total_engagement': 0,\n",
    "                    'sentiment_overview': {},\n",
    "                    'key_insights': []\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def update_post(self, research_id: str, post_data: Dict) -> None:\n",
    "        \"\"\"Update post information\"\"\"\n",
    "        if research_id in self.data:\n",
    "            self.data[research_id].post = post_data\n",
    "        else:\n",
    "            raise KeyError(f\"Research ID {research_id} not found\")\n",
    "    \n",
    "    def add_reply(self, research_id: str, reply_data: Dict) -> None:\n",
    "        \"\"\"Add a reply to the research data\"\"\"\n",
    "        self.data[research_id].interactions['replies'].append(reply_data)\n",
    "    \n",
    "    def save_research(self, research_id: str, filepath: str) -> None:\n",
    "        \"\"\"Save research data to JSON file\"\"\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(self.data[research_id].to_json())\n",
    "\n",
    "class RedditResearchAgent:\n",
    "    \"\"\"Main agent coordinating the Reddit research process\"\"\"\n",
    "    def __init__(self):\n",
    "        self.gemini = GeminiWrapper(temperature=0.6)\n",
    "        self.reddit_api = RedditAPI()\n",
    "        self.subreddit_agent = SubredditAnalysisAgent(self.gemini)\n",
    "        self.prompt_agent = PromptGenerationAgent(self.gemini)\n",
    "        self.response_agent = ResponseAnalysisAgent(self.gemini)\n",
    "        self.data_agent = DataCollectionAgent()\n",
    "        \n",
    "    async def run_research(\n",
    "        self,\n",
    "        research_prompt: str,\n",
    "        subreddit_name: str,\n",
    "        research_id: str = None\n",
    "    ) -> Optional[str]:\n",
    "        \"\"\"Run the complete research process\"\"\"\n",
    "        if research_id is None:\n",
    "            research_id = f\"research_{int(time.time())}\"\n",
    "            \n",
    "        # Initialize subreddit\n",
    "        subreddit = self.reddit_api.get_subreddit(subreddit_name)\n",
    "        if not subreddit:\n",
    "            print(f\"Could not access subreddit: {subreddit_name}\")\n",
    "            return None\n",
    "            \n",
    "        # Analyze subreddit and generate post\n",
    "        style_template = await self.subreddit_agent.analyze_subreddit(subreddit)\n",
    "        post_content = await self.prompt_agent.generate_post(style_template, research_prompt)\n",
    "        \n",
    "        # Initialize research data\n",
    "        self.data_agent.initialize_research(\n",
    "            research_id,\n",
    "            research_prompt,\n",
    "            subreddit_name,\n",
    "            style_template\n",
    "        )\n",
    "        \n",
    "        # Make the post\n",
    "        try:\n",
    "          post = subreddit.submit(\n",
    "              title=post_content.split('\\n')[0],  # First line as title\n",
    "              selftext='\\n'.join(post_content.split('\\n')[1:])  # Rest as content\n",
    "          )\n",
    "          \n",
    "          # Create post_data dictionary\n",
    "          post_data = {\n",
    "              'id': post.id,\n",
    "              'content': post_content,\n",
    "              'timestamp': datetime.utcnow().isoformat(),\n",
    "              'status': 'active'\n",
    "          }\n",
    "          \n",
    "          # Update with post data\n",
    "          self.data_agent.update_post(research_id, post_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error posting to Reddit: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "        # Monitor responses\n",
    "        start_time = time.time()\n",
    "        generated_replies = set()\n",
    "        \n",
    "        while time.time() - start_time < Config.monitoring_duration:\n",
    "            try:\n",
    "                # Refresh post by getting a new instance\n",
    "                post = self.reddit_api.reddit.submission(id=post.id)\n",
    "                \n",
    "                # Check if post was removed\n",
    "                if hasattr(post, 'removed_by_category'):\n",
    "                    print(\"Post was removed by moderators\")\n",
    "                    self.data_agent.update_post(research_id, {\n",
    "                        'status': 'removed',\n",
    "                        'timestamp': datetime.utcnow().isoformat()\n",
    "                    })\n",
    "                    break\n",
    "                \n",
    "                # Process new comments\n",
    "                try:\n",
    "                    post.comments.replace_more(limit=0)  # Changed to 0 to avoid rate limits\n",
    "                    all_comments = post.comments.list()\n",
    "                    \n",
    "                    for comment in all_comments:\n",
    "                        if (comment.id not in generated_replies and \n",
    "                            self.response_agent.should_reply(comment, post.score)):\n",
    "                            \n",
    "                            # Analyze comment\n",
    "                            sentiment = self.response_agent.analyze_sentiment(comment.body)\n",
    "                            \n",
    "                            # Store comment data\n",
    "                            comment_data = {\n",
    "                                'id': comment.id,\n",
    "                                'content': comment.body,\n",
    "                                'upvotes': comment.score,\n",
    "                                'sentiment': sentiment,\n",
    "                                'timestamp': datetime.fromtimestamp(comment.created_utc).isoformat(),\n",
    "                                'is_bot_generated': False\n",
    "                            }\n",
    "                            self.data_agent.add_reply(research_id, comment_data)\n",
    "                            \n",
    "                            # Generate and post reply if needed\n",
    "                            if len(generated_replies) < Config.max_replies_per_thread:\n",
    "                                context = f\"Original Post: {post_content}\\n\\nComment: {comment.body}\"\n",
    "                                reply_content = await self.response_agent.generate_reply(context)\n",
    "                                \n",
    "                                try:\n",
    "                                    reply = comment.reply(reply_content)\n",
    "                                    generated_replies.add(reply.id)\n",
    "                                    \n",
    "                                    # Store reply data\n",
    "                                    reply_data = {\n",
    "                                        'id': reply.id,\n",
    "                                        'content': reply_content,\n",
    "                                        'upvotes': 0,\n",
    "                                        'sentiment': self.response_agent.analyze_sentiment(reply_content),\n",
    "                                        'timestamp': datetime.utcnow().isoformat(),\n",
    "                                        'is_bot_generated': True,\n",
    "                                        'parent_comment_id': comment.id\n",
    "                                    }\n",
    "                                    self.data_agent.add_reply(research_id, reply_data)\n",
    "                                    \n",
    "                                    # Respect rate limits\n",
    "                                    await asyncio.sleep(Config.rate_limit_delay)\n",
    "                                    \n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error posting reply: {str(e)}\")\n",
    "                                    continue\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing comments: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Wait before next check\n",
    "                await asyncio.sleep(Config.check_interval)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error monitoring responses: {str(e)}\")\n",
    "                await asyncio.sleep(Config.check_interval)\n",
    "        \n",
    "        return research_id\n",
    "\n",
    "\n",
    "# Usage example\n",
    "async def main():\n",
    "    redditApi = RedditAPI()\n",
    "    redditApi.verify_reddit_credentials()\n",
    "    agent = RedditResearchAgent()\n",
    "    research_prompt = \"What features do users want in next-generation smartphones?\"\n",
    "    subreddit_name = \"Smartphones\"\n",
    "    \n",
    "    research_id = await agent.run_research(research_prompt, subreddit_name)\n",
    "    if research_id:\n",
    "        print(f\"Research completed successfully. ID: {research_id}\")\n",
    "    else:\n",
    "        print(\"Research failed to complete\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
